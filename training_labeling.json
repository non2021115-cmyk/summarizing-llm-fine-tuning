[
  {
    "id": "sum_001",
    "summary": "Dr. Carroll's diverse background in physics, biology, and computing led to a career combining computational skills with genomics research.",
    "original_text": "We've all read about Dr. Ankero's background. So you know about his work at Gogleaya DI Nexis and his research contributions. What I want to talk to you about is why this conversation matters for you. So you are first year students your learning Python stats and sub machine learning you might be wondering where these skills actually lead. What does it look like to use data science in the real world? How do you go from learning algorithms in class to solving actual problems that matter? Now Andrew's career shows you one path. He started off with biology and physics added computational skills. It now means AI strategy for genomics at one of the biggest Tech companies in the world."
  },
  {
    "id": "sum_002",
    "summary": "Continuous learning at each career stage—combining computational with experimental work, understanding customer needs, and developing product strategy—was essential for career growth.",
    "original_text": "But here's what's useful for you. At every stage. He had to learn new things in graduate school. He learned to combine computational with experiments at DAN Nexus he learned to work with real customers who had real problems and at Google he learned to think about product strategy not just research. The topic we'll discuss today connects directly to what you're studying. You're learning about data analysis. Andrew works with one of the largest biological data sets in the world. You're learning about AI and machine learning. Andrew uses these tools to help doctors interpret genetic information and help companies develop new medicines."
  },
  {
    "id": "sum_003",
    "summary": "Career decisions like transitioning from academia to industry require asking practical questions about skill readiness, collaboration with non-technical people, and what interests you beyond what's taught in class.",
    "original_text": "But more than technical skills I think you'll find it valuable to hear how he made decisions. Why leave academia for a startup? How do you know when you have the right skills for a job? What do you need to learn that they don't teach you in class? How do you work with people who aren't data scientists like doctors or biologists? So I went to graduate school with Andrew and one thing that I've always appreciated is that he's really practical. He doesn't just think about what's scientifically interesting he thinks about what actually works and what actually helps people and that's a mindset that will serve you well whether you end up in Tech companies, research, health care or anywhere else."
  },
  {
    "id": "sum_004",
    "summary": "Students should think about what problems interest them and what skills they want to build, rather than having everything figured out immediately.",
    "original_text": "So as you listen today and ask questions, think about your own path. You don't need to have everything figured out right now. Dr. Carroll certainly didn't but you can think about what problems interest you, what skills you want to build and where you want to go please welcome Dr. Andrew K."
  },
  {
    "id": "sum_005",
    "summary": "Three major reasons drive genomics use: 6% of people have rare genetic disease risks, 30% of health outcomes stem from genetics, and genetics enables novel drug development.",
    "original_text": "So first off, like why do you want to use PS? There's really three major reasons. So one is that in about 6 percent of individuals there is some rare genetic event which dramatically increases the risk of disease. For example, diseases like cystic fibrosis or a substantially elevated chance of breast cancer. In addition, around 30 percent of health outcomes are a result of genetic predispositions. And finally, the intersection of those two enables you to use genetic information to develop novel therapeutics. So genetics is widely used in drug discovery."
  },
  {
    "id": "sum_006",
    "summary": "Genome sequencing costs have decreased super-exponentially from hundreds of millions to around $200, driven by new technologies including AI-enabled innovations.",
    "original_text": "So a few things that are transforming the field. One is that there has been a super exponential decrease in the cost of sequencing the genome. So the line that you see is the scaling of Moore's law, which is itself exponential and then plotted. You can see how the genome has gone from costing hundreds of millions of dollars through now you can get it for around 200 or so. And this is in part driven by recent innovations in sequencing technology. And some of those are enabled by AI which crosses S within the drug development space."
  },
  {
    "id": "sum_007",
    "summary": "Drug development has low success rates (only 10% of compounds work) and high costs, making genetic evidence crucial for focusing on compounds with higher success probability.",
    "original_text": "Drug development is largely driven by finding a needle in a haystack hits. This is an example for the dog behind Moosepic. And an interesting property is that drug revenue, as this chart indicates, is actually largely driven by the North America bin market. And that's because in North America they don't aggressively negotiate for drug pricing because they don't have universal health care. So right now companies are investing in order to find the large high revenue driving hits and especially on the full dry record in the North American market. So one very interesting property about drug development is that it mostly doesn't work. So this is the pipeline from you know, how many compounds we have to screen to an actual kit. And going from, you know, when you have put in a fair amount of effort into a compound, only around 10 of them will actually become a drug."
  },
  {
    "id": "sum_008",
    "summary": "Companies like Regeneron sequence millions of individuals with their phenotypes to find genetic associations with traits like cholesterol, driving new drug therapies.",
    "original_text": "So within drug development, you have this then on the high revenue and also a low probability of success. So one of the reasons that people want to use genetic evidence is because when you have these multiple types of evidence, you have a higher probability of having that compound eventually be a success. And if you're putting in a billion dollars in order to, you know, develop a compound, then you could save an enormous amount of money by focusing effort on that compounds with the highest probability of success. So some work that we get to participate in because of that property of drug compounds have better support when they have genetic evidence behind them. So we've worked with pharmaceutical companies like Regeneron, which has this large catalogue of a million individuals that they have the genome sequencing for and they also have the phenotypes. So they've gone into the hospital and got information about these books in order to find the associations. And that's really done by looking for traits of interest and correlating genetic variants with you know, for example, a reduction in cholesterol which drives drives new cholesterol, low therapies."
  },
  {
    "id": "sum_009",
    "summary": "Dropping sequencing costs enable multi-omics approaches—sequencing DNA, RNA, and proteins—to understand cell states and disease transitions at unprecedented scale.",
    "original_text": "Another change that's occurred is because the scale of information because the scale of sequencing has grown so much, people are looking for all sorts of new ways to understand samples. So this chart shows how information flows within a cell. So DNA is like a hard drive and it writes information into RNA which is sort of like the RAM it's the short term storage and that RNA becomes proteins. So because the cost of sequencing has dropped so much, it's become feasible to like for DNA, you would only sequence these two copies. There's one from your mom and one for your dad. But because the cost has dropped so much, it's starting to get more feasible to sequence the transcript as well. Just the RNA and that's driving these new multi omics multi dimensional no one was talking about D."
  },
  {
    "id": "sum_010",
    "summary": "Sequencing RNA from different cells reveals their states and what pushes cells between healthy and diseased conditions, enabling therapeutic development.",
    "original_text": "This is an area where I, it sounds very active in terms of understanding the space. So that is allowing us to look more at how cells themselves behave. So because RNA represents the essentially the Rola, you can sequence these different cells and understand things about their state. You could build these large multi dimensional matrices of what genes are expressed in each different cell to try to understand what pushes one cell into a healthy state or into a disease state and what compounds you could get to move cells from disease to healthy states."
  },
  {
    "id": "sum_011",
    "summary": "As data capacity expands exponentially, the key challenge becomes integrating multiple dimensional datasets—a common theme throughout data science.",
    "original_text": "And one of the things that that manifests in is you're going out to starting to develop these chips which have a cell for an entire organism bar codes for all the different. And you can look at what these cell types are, what they're doing. So as the sequencing capacity has expanded exponentially, that is unlocking the ability to ask new questions especially multi dimensional questions bringing in lots of different sets. And this is going to be a very common theme throughout everything in data science of, as you can bring in more data the challenge is to integrate all this information."
  },
  {
    "id": "sum_012",
    "summary": "Growing up in Louisiana/Virginia, studying physics and biology at UVA with a focus on computing classes proved to be a fortunate career foundation.",
    "original_text": "So then the next section is my background. And actually when NOA talked about what are the decisions that are made that's quite, that's quite interesting. It's not something that I think about so much but let me just go through it. Okay so I grew up in Louisiana, Virginia. I did a bachelors, as Noah said, in physics and biology. After that I went to Stanford where I met Noah for a PhD in plant genomics and focusing on evolution."
  },
  {
    "id": "sum_013",
    "summary": "Double majoring in physics alongside biology was a 'fortunate accident' that became one of the most valuable career decisions, especially the computing courses.",
    "original_text": "Okay so Bachelor's at UPA Physics and Biology so I knew when I came in I wanted to do science but I didn't really know how to do it or what the best way to study was. I was, you know, looking back I was maybe a little bit naive but at the time also I just thought, well, you get your degrees and then you go to a lab and then you become a professor and that's kind of like how science has done. You write some papers and things like that. And so I had planned on biology but I liked physics and I had enough courses that I needed to take that if I was strategic to back on them, I could do a second major. So I decided to do physics, which is maybe a slightly random decision at the time but it was probably one of the most valuable decisions you know, looking back in my life. And actually it's quite funny. A lot of the valuable decisions turned out to be fortunate accidents."
  },
  {
    "id": "sum_014",
    "summary": "Computing classes were so enjoyable that hours flew by working on problem sets, drawing him toward computational work without initially considering economic value.",
    "original_text": "So as part of physics, I took computing classes and actually when I took the computing class, I absolutely fell well with it. The first one I to, you know, I would go to all my Pino classes and then I would go to the physics classes and then I would go to the computing class and then I'd give the problem sets and I would just, I would just love to spend hours and hours in the computer science problem sets. They were the most fun and so that like help me. I wanted to gravitate towards that area and I also wasn't thinking about it being particularly economically useful. So it was again heavy accident."
  },
  {
    "id": "sum_015",
    "summary": "Undergraduate lab work in immunology was okay but unremarkable; having a quantitative physics background made biology PhD applications stand out.",
    "original_text": "So I did lab work in ammunology lab. I would think I was okay in the lab. I don't think I published any papers as part of my undergraduate, which is not that unexpected. It was an interesting experience but it wasn't like a typical standout thing. And to be honest, I didn't really understand what what looked good for graduate school application. So I knew I wanted to do a PhD but I know I'll just take these courses and I'll try to do really well on them but I didn't really have a strategic thought about what to take. And I think in that sense I got quite you lucky because I think so when I plied to many schools I generally like it they virtually all accepted me. And I actually think those are the quantitative fact I applied to the biology programs and I think having a physics degree having like quantitative background looks unusual for those applicants because I think otherwise I'm not really sure if my application is here to stand out. So I think that was just getting lucky."
  },
  {
    "id": "sum_016",
    "summary": "Switched from immunology to plant genomics because killing mice all day was unbearable; chose plants over animal experiments despite valid research goals.",
    "original_text": "So PG at Stanford, I went into a lab that did plan moms and actually one of the reasons for that is I hated film mice, an amology. There was a lot of filling mice. There was one day an undergraduate I went to the lab and I started filling mice at 8 am and I stopped filling mice at and 7 PM and I was like I can't do this I'm done I'm bring the plants and actually it's not I mean this is, it's the reason to kill these mice were to understand how the cell immune system activates based on exposure to viral infection. So it's, you know, it's, it's good valid research to improve humanity but I didn't have the summit for it and I'm from filling plants. So I went into a plant, a laboratory plants."
  },
  {
    "id": "sum_017",
    "summary": "The most critical PhD skill is learning real science—understanding what's known versus unknown by watching how experienced researchers think and publish.",
    "original_text": "And the most important thing about PhD is learning to do real science. By far, the strongest skill to learn is thinking about where's the boundary of the field? What do people know? What do people not know? And actually one of the ways to think about it is if you think about all of your colleagues trying to do science, there's like they're trying to push the field forward. The best thing to do is watch what they're thinking about watch what the post starts. For senior graduate students what are they thinking about as they publish papers? What do they think will make a compelling piece of evidence? And a lot of it is like, you know, like when you're a kid, you sort of like tap through you, sound out words to learn how to speak. And science is sort of the same way like you are trying to mirror the actions of the people who have experience only are early graduate students."
  },
  {
    "id": "sum_018",
    "summary": "Wetlab work was too slow and hard to reproduce; computational work offered fast turnaround and determinism, leading to full transition by third year.",
    "original_text": "That's really useful. I said I'm very practical. I think that is true. Now I don't think I was like practical or not practical at the start of my PhD. I think a lot of that comes from just like watching the, watching people who are trying to do science because they've been, they learn how to do things in a very practical way. And I think that comes as well. So I liked to do wetlab work but I found it too slow and it's also difficult to reproduce. Things like biological systems are very complicated whereas with computer systems historically you have full control of them. Now with some of the generative AI systems in large Numage models, you conceptually have full control but you may not understand everything that you're doing because in that sense actually computer science is becoming a little bit more like biology. But I was really drawn to the fast turnaround times and the determinism in informatics. So around the third year I became fully informatics based."
  },
  {
    "id": "sum_019",
    "summary": "Fully computational by third year, trained one undergraduate annually to do experiments while making predictions; field transformed from 5 to 23 plant genomes during PhD.",
    "original_text": "So I basically only a program and each year my advisor was kind enough to give me one undergraduate to work with. I was always somebody in the biology program and I taught them how to do all of the experiments and then I made all the predictions and we worked together and eventually you know, they were doing all of the experiments and they would graduate and then I would teach the next one. That was very rewarding. And at the time when I started my PhD, there were five complete plant genomes and by the time I graduated my PhD, they were 23 and it was really just at this tipping point of the field or the cost of sequencing in that graph. It was just at the point where the cost went down by many, many orders of magnitude. So that field was undergoing a complete transformation in the amount of data that was available."
  },
  {
    "id": "sum_020",
    "summary": "Cost drops made individual genome sequencing possible (e.g., $100k per person), enabling disease diagnosis rather than just sequencing one representative genome.",
    "original_text": "And actually one of the things that allowed at the time is this shift from we used to sequence one representative individual and so it would be the human genome. But when the cost drops so dramatically, it begins to become possible to sequence individuals. So you could ask, you know, try to diagnose genetic diseases you could sequence one individual and it would be, you know, at this time maybe 100,000 dollars which you know, was tractable in a way it hadn't been before."
  },
  {
    "id": "sum_021",
    "summary": "Brief postdoc at Lawrence Berkeley Labs supporting 100 scientists was extremely rewarding—one evening of programming solved their data problems and earned paper authorship.",
    "original_text": "But after that I did a very brief post doc at Lawrence Berkeley Labs. But I got that role by connections I had worked with the principal investig you know, he knew my work and he needed to hire an informatician for the center. So it was very, you know, I do a job search. I kind of talked with him actually I did it turned down a faculty job in Australia for like two body problem reasons and decided to go to Lawrence Perky Labs. Instead I had a computational role. I was given support for 100 different scientists. They would do their lab work and then they would take me their data and they would be, they would come, you know, there's really I have this Excel data sheet with all this huge data I don't know how to make sense of it and it would be like one evening of programming and I would give them like figures and plots and they would be so incredibly grateful and they would put me on the paper that I had done in my thing so little. And so it was an extremely rewarding job because it was, it was a place where people just really needed a little of data science and they were so grateful to have that problem solved. So this is potentially one of the most rewarding jobs I had. I had so much fun."
  },
  {
    "id": "sum_022",
    "summary": "Turned down faculty position in Australia because girlfriend worked at Google and Adelaide had no good options for her; concluded industry could offer good science.",
    "original_text": "It wasn't a very well paying job but ultimately my girlfriend worked at Google and like we had this discussion when I was with the faculty offer from Australia it was an Adelad were we going to move to Adelaide? And so she looked up for options and like there was, there's nothing in Adelade like she could teach in university and she didn't want to do that. And, and she could go to Sydney and be in Google and Sydney but then it would be like a 24 hour train ride and it was just not going to work. And I concluded it was going to be very difficult because what am I going to do? I'm going to make my girlfriend give her like high pen Google job. So I can, you know, take an academic job. It just, it actually didn't seem fair. And so I concluded it was going to be very difficult in the long run. So I remember waking up one morning I just decided I don't know why I just decided I think actually industry is a better place. And I, I sorted to the conclusion that you can do science in academia or you can do science in industry. And the more important thing is for you to be thoughtful about the roles that you choose where you can find the ones that align with the way that you want to do science which is how I've chosen every rule since then and I think it d okay so DNA Nexis I again landed this role by connections and one common theme you'll see is every job I had I got via connections to the other."
  },
  {
    "id": "sum_023",
    "summary": "Networking is critical—every job came through connections who understood his capabilities, not through cold applications or hiring managers.",
    "original_text": "You know, do the hiring managers basically networking among people, making sure they understand what you can do is very important for producer. This has just always been what works for me."
  },
  {
    "id": "sum_024",
    "summary": "Joined DNA Nexus as only application scientist among 19 people; first year was extremely difficult with delayed product launch and company nearly dying.",
    "original_text": "So I started in an application scientist role. I was the only person in the company hired at that position. There were people who were engineers who were building the underlying infrastructure. There was like a couple of salespeople, legal people, leadership. I was the only person who was the scientist who build at the time the company was series beat and it had a couple rounds of funding. It had gotten 15 million dollars. There were 19 people at the company and we didn't have a product and the first year was extremely difficult. We were supposed to launch the platform in May and that didn't happen. We didn't launch the product until a year following. And because of the way investment works, it seemed very likely that the company was going to die."
  },
  {
    "id": "sum_025",
    "summary": "Leadership team was replaced by investors after company nearly failed; got lucky being assigned to critical project that saved the company and enabled career progression.",
    "original_text": "So I was prepared to look for a new role but I thought, you know, it's kind of it was an interesting job. I liked building the applications even if we didn't have any customers yet. I thought it made sense to just see what's going to happen. I thought I would learn a lot at least from the processing. So the CEO and the full leadership team was replaced and they brought in the investors decided because the investors went through and they talked with everyone in the company and the investors made the decision that the idea of the company was valid. And so they decided to, you know, give Bridge loan to keep the company alive and replace the leadership. And I got extremely lucky that I was assigned to the project that was the do or die for the company and that project worked and the company was able to raise money and like have this very strong demonstration. So I'm not sure what takeaway what just I think it's important to acknowledge the times when you just got lucky to be put into the position and if I hadn't been able to deliver it, then it wouldn't have worked. But I got the chance to do this project. And from there that was Mica. That was a critical point in me being able to get promoted into a leadership positions."
  },
  {
    "id": "sum_026",
    "summary": "Company reinvented itself every two years feeling like completely different jobs; scaled from startup to market leader with customer adoption.",
    "original_text": "Okay, the second two years and actually every two years at the company, I feel like the company reinvented itself and so the job was totally different. So it was almost like doing a different job every two years. So then the company we started to scale we got products to the market we got adoption we became one of the early leaders in the space. I was promoted to Director of Science. I hired a team of five people. I got to present to the investors about to travel to China. We got our first series sea round from Woshi BioTech got to talk to all the investors in subsequent rounds I do some combination of working with the customer accounts, building new applications start thinking about what it means for your company to become commercial. Work with all the engineers on what are the products that we're going to need like system properties we're going to need for all these folks and if not, them both around or so people."
  },
  {
    "id": "sum_027",
    "summary": "Promoted to VP then Chief Science Officer with 30-person team; learned about company strategy, investors, and board dynamics while transitioning from building to commercial operations.",
    "original_text": "And so then in the third two years, I was promoted into the of science and eventually the Chief science officer. And there the team grew through an organization of 30 people. They had to take the initial five people and move them into management roles. So they also moved up this kind of like career transition but they were starting to get their own teams, get their own specializations. Think about what is the company's strategy how does that, you know, build? How does that relate to what investors want? How does that relate to what the board wants? It's like sitting in the executive meetings, which I don't think I was ready at the time to really appreciate how useful and how much information there was. And the company transitioned to be more revenue oriented to move more towards professional services are building less things and really growing up as a company which is something that all companies do as they age. But that moved me more towards more towards, like commercial operations. And that was not kind of in the direction of building things that I wanted to do."
  },
  {
    "id": "sum_028",
    "summary": "Company shifted toward revenue/services rather than building new things; role no longer aligned with desire to build, prompting transition to Google.",
    "original_text": "And the, the CEO shifted the structure of the team. So he moved like the professional services to kind of within engineering and asked me to do some other things. And so that didn't really give, I really wanted to build things. And so this is just a case that the company grew in a way that was just separate from the work that I wanted to do. And so that's why I needed to transition to Google. And again, at Google I got the role by connections."
  },
  {
    "id": "sum_029",
    "summary": "Got Google role through someone he'd collaborated with across multiple jobs; now in product management but day-to-day similar to DNA Nexus work.",
    "original_text": "So I actually at DNA Axis had worked with somebody who was at a place called the Grog Institute. I was an academic place and then he moved to a startup and then he moved to Google as well. And I had worked with him collaborating on a number of different projects. And then when he was at Google, we worked together on some of the software that he built like he put it into Bexus. So when it was the time to transition, I asked him, would you know, is there a role for me there as well? And he said, yeah they wanted to have that role. So I transitioned to product management. But really my day to day, my perspective looks quite a bit like the way it looked at data analysis in the sense that we're a small team we have a set of stakeholders we have to make happy both like externally and internally. We build open source applications. I work with a team of engineers."
  },
  {
    "id": "sum_030",
    "summary": "At Google, translates genomics community needs to engineering team and explains genomics to leadership unfamiliar with the field; small team generates reputational value.",
    "original_text": "One of the reasons they have me on is to work with the genomics community to sort of translate the things that we're building to the things that the genomics community needs. And there's lots of managing up to folks that don't understand genomics, right because above me in the leadership chain folks are more familiar with with Google research as a general research entity. And then of course with Google has a commercial entity as well. So it's really the case of having a small theme that doesn't have a commercial expectation and so it has to generate enough reputational value that the rest of Google's leadership feels that it's worth the let me pause and check in with Mila again."
  },
  {
    "id": "sum_031",
    "summary": "Genome is 3 billion characters; sequencing fragments it into pieces that must be mapped to reference genome and reconstructed—a very hard computational problem.",
    "original_text": "All right I'm going to go through this quickly but this is some of the cool stuff we do okay so the genomes about three billion characters long and genetic variants code for proteins. Those proteins relate to diseases. So we want to find genetic variants so we can figure out what's wrong with false. OK when you read a genome, it fractures it into lots of little pieces. You map it to this reference genome and you need to figure out what that final sequence is. It's a very hard overall problem. Basically everything we do in biology we are stealing the machines of nature because we can't build things that are as good as what nature has built for almost all bioteche stuff."
  },
  {
    "id": "sum_032",
    "summary": "Two main sequencing technologies: light-based (laser detecting labeled DNA) and nanopore (threading DNA through protein pore reading electrical signals)—both single-molecule requiring AI.",
    "original_text": "Okay so how do some of these things work? I'll just give an example. So we have light and basically we label compounds we shine a Laser and it looks at the individual DNA molecules copying and then we kind of note the signal that appears and that is how we can figure out these individual faces. Okay the other way that we do it is we take this pore and we have a protein membrane and there's a motor protein that threads the DNA through the pore and this is above a semiconductor CH and that semiconductor CHiP we need the difference in electrical signal and can produce bases this. So these are both single molecules so very hard to accurately do. That's why we need AI."
  },
  {
    "id": "sum_033",
    "summary": "AI approaches range from statistical (fast, interpretable, inflexible) to deep learning (flexible, slower); team builds across spectrum with deep learning as biggest differentiator.",
    "original_text": "Okay so how do we use AI to analyze genomes? And so in general there's, you know, this progression of ways that you can use computer models you can have like statistical approaches which are very intrcable and extremely fast but they're not very flexible. You can't solve like very open ended, super complex problems. And then on the right hand, you have my deep learning and generative AI applications which are extremely flexible but can be a little bit slow. So our team built stuff at all of these different levels. But the biggest differentiator is in this deep learning where we're trying to the training models perform complex tasks but still be fast enough to operate on the SEN in real time."
  },
  {
    "id": "sum_034",
    "summary": "Models trained through examples using convolutional neural networks; presenting information the same way computational biologists see it helps models learn to interpret it.",
    "original_text": "Okay you trained models through examples show lots of individual things. These are a convolutional neural that you've probably encountered in your courses. In general this practice problem is one that computational biologists do themselves. So if we present the information in the same way, they should be able to figure that out. Okay this is how a human looks at the information themselves but we're trying to structure that information in the same way that computer can use."
  },
  {
    "id": "sum_035",
    "summary": "DeepVariant uses CNN to analyze multidimensional images and determine if variants come from one parent, two parents, or are sequencing errors—won FDA competition.",
    "original_text": "So one of the first pieces of software that we built is called deep variant. What it does is it takes these multidimensional images on the left, uses a convolutional neural network and it has a series of probabilities of whether a variant is present from one parent or two parents or if it's just an error from sequencing. So there was a competition hosted by the FDA where this one the highest accuracy in multiple different sequencing technologies. And the way that we train this data is that the National Institute and Standard of Technology produces these reference cell lines have been extremely well characterized. So we know all the genetic variants that are present. So we can show millions of examples from these cell lines to train the Model. All of our software is open source so you can go to any of the G hubs and look at all the code there."
  },
  {
    "id": "sum_036",
    "summary": "Rapid diagnosis is critical for newborns with genetic conditions requiring urgent treatment decisions—huge array of tests done to determine cause.",
    "original_text": "Okay so one application that we've worked on is diagnosing individuals in a time critical manner. So specifically often when a baby is born, there can be a genetic condition which requires extremely rapid diagnosis. And there's this huge array of tests that are done all in color to try to figure out what's, what's wrong with the individual. It's also true for, you know, for older folks as well but it's most common to occur near birth."
  },
  {
    "id": "sum_037",
    "summary": "Stanford pilot used rapid nanopore sequencing in ICU to diagnose genetic conditions in under 8 hours versus 4-8 weeks for traditional tests.",
    "original_text": "Okay so one of the projects that we did was a pilot with Stanford to apply this nanopore technology which was very rapid to sequence the genome in ICU in Stanford. So one of the cases, there was a pilot of 13 individuals."
  },
  {
    "id": "sum_038",
    "summary": "13-year-old boy with sudden heart failure sequenced in under 8 hours; identified variant in structural protein, diagnosed genetic condition requiring transplant, received heart before traditional test results.",
    "original_text": "One of them was this 13 year old boy who had a sudden onset of heart failure and he was, he deteriored very rapidly and was rushed to Stanford Children's Hospital and was put onto a heart and lungs support machine which is sort of the last ditch effort to keep folks alive. And so the question is why does this individual have disease? So if it is something like an infection, then this is reversible. And so the thing to do is just to support the patient and the patient will recover but if it's a genetic cause, then this is not going to recover. So the person needs to be listening for transplant as soon as possible and you've got to figure this out as fast as you can because you only have so much time okay so by sequencing this individual, by sequencing mathiew, we are identified a single variant in this structural protein which conveys force from the heart muscle as it beats. And by identifying that variant that is sufficient to diagnose as a condition that will not get better with time and that he will need a transplant. So all of this occurred in less than 8 hours. So by the time we got the award for the fastest genetic diagnosis and so he was able to be, he came into the hospital, he was sequenced, the variant was identified and he was listed for a heart transplant and received the heart before the turnaround time for traditional test, which is something like four to 8 weeks."
  },
  {
    "id": "sum_039",
    "summary": "Two-month-old girl with kinase variant diagnosed with specific epilepsy form that had specific treatment; patient treated and discharged in same hospitalization.",
    "original_text": "There was another case of a little girl, two month old girl who had a variant in kinase. This is another protein structure which made it possible to diagnose a specific form of epilepsy and that form of epilepsy had a specific treatment. So we're able to take in the patient, identify the causal variant and then treat and discharge the patient in the same way."
  },
  {
    "id": "sum_040",
    "summary": "Single-molecule sequencing has high error rates; DeepConsensus sequences molecules repeatedly to achieve 99.9% accuracy using transformer models like in ChatGPT.",
    "original_text": "Let's see. I'm going to quickly go through how we're using AI to improve sequencing as well. So that single molecule has a very high error rate. So one of the things you can do is you can sequence that molecule repeated times to try to increase the accuracy to 99.9 percent. So this is the way information looks like through a Model. And you might notice this looks a lot like a language problem like you could Model this instead of like, basically you could think of it as French or English."
  },
  {
    "id": "sum_041",
    "summary": "DeepConsensus uses transformers to translate error-prone sequences to correct sequences; trained by masking characters, now installed on PacBio instruments for primary sequencing.",
    "original_text": "So what we did is we took transformers, the T and chapchbt to essentially make something that will take in error probe sequence and output the B sequence. And this is done by masking the characters and then learning to predictive to actually standard way that you train transformers. So that Model is a deep consensus. The architecture chosen was specific to make it very fast and this is something that was installed on the Pack Wile instrument. So every time this instrument runs deep consensus produces the primary P."
  },
  {
    "id": "sum_042",
    "summary": "All genomics projects are extremely multidisciplinary with clinical doctors, sequencing operators, instrument builders, and computational analysts working together.",
    "original_text": "So I think so one of the things like all of the projects that you see are extremely multidisciplinary like if you've done research, if you've looked at the papers that we have, there's like a huge number of people and they have all sorts of different specialties like in the diagnosis project you have the clinical doctors you have the folks who are running the sequencing instruments you have the folks who are building the sequencing instruments you have us who are building the analysis."
  },
  {
    "id": "sum_043",
    "summary": "Students have freedom to choose their computational depth; key skill is collaborating and speaking the language of other specialties to interface skills effectively.",
    "original_text": "So I think there's a huge amount freedom for you to figure out what mix of computational work is right for you. And I think the most important thing is to be able to collaborate to just kind of speak the language of other folks and interface like the skills that you have built with the things that they're doing. So that if you want to be like purely computational, then you can do that and with the right connections figure out how to put that what other people are doing. And if you prefer to be more vibrant and more on a different area, that's your option too. I think that as these projects become so large and so complex, it actually gives a lot more opportunity for you to sort of define the best role that you want in the given project."
  },
  {
    "id": "sum_044",
    "summary": "Two types of AI: specialist systems for complex problems with big data, and generative AI—the big question is how generative AI will be useful in 10-15 years.",
    "original_text": "Of health care and life science over the next 10 to 15 years all right so it's a great question. I think you have to break this into two ways that they light can operate. So the projects that I talk about are sort of like specialist AI systems that they operate on big data sets that are not language based, literature based. They're really about solving specific problems extremely well. So this type, this type of approach has the challenge of solving really complex computational problems in a new and specialized way. And I think that that like you can go into this area and specialize and I think that's one to just continue."
  },
  {
    "id": "sum_045",
    "summary": "Generative AI's future role unclear—can it take case queries and give reliable answers? Currently conditionally useful for researchers but doesn't make humans much faster.",
    "original_text": "So the big open question right now is actually what is the role of generative AI approaches going to be? Is there one which I understand literature? Can you know when you have a query please solve my case but you can put in the case, put in the variant and have a large language Model like Chat Chi Kit or whichever I might give you an answer. And at this time we can find a few things that these are conditionally useful for. So you can build systems that are able to take that information and will probably help researchers but it's really a lot more of a collabor. I'm not sure the human does it all that much faster than with this technology. And I'm saying that to somebody who's like worked with and built some of these technologies."
  },
  {
    "id": "sum_046",
    "summary": "Key question for next 10-15 years: how can flexible AI systems that process images and text gain confidence for medical use—need to distinguish useful facts from hallucinations.",
    "original_text": "So the big question in AI for 10 to 15 years which I don't think can be answered right now is what are the ways that you could use these very flexible systems that could take in images and take in texts and can give you an opinion about a case about a research topic, about a novel scientific hypothesis. How do we gain the confidence that the outputs of that are as good as better or useful to humans? And one of the things that'll be most important to watch and build an opinion of what are the systems that you construct which will be able to use those in a positive way and I can't tell you in advance how that specifically is going to work."
  },
  {
    "id": "sum_047",
    "summary": "Learning AI implementation is hard—best approach is finding working examples of interesting problems, building from there without frustration, focusing on application over theory.",
    "original_text": "All right and the third floor, I think I have some I'm studying in the college and I have a question about I was like studying about the neural networks and KIM to LMM and also some machine learnings. But after studying I could learn about the structures and how it works in what are them. But implementing by the real cold in Python or Adjson some files it was so hard so I could only just make the code by crawling some other people's code and even though I get the code, I cannot adjust them and cannot change them without the AI's help. And also even the running the code was so hard for me. But I was trying hard but I think I'm stuck in some place and coming up with walls. But how can we overcome this problem? I think one of the first things is one of the best ways to learn it is to find something that starts to work like find a problem that you find interesting and find a way of using a program that gives you output and then like build from that like I feel like when you first approach a new system, it can be very complex. You need to build the skills over time to understand how to use it and that actually is going to occur as you use it. You just have to find a way to not get frustrated. And the best way to not get frustrated is to start with certain interesting things that, that work. So one component is like picking the right problem."
  },
  {
    "id": "sum_048",
    "summary": "Most people should learn to apply AI to problems rather than develop new methods; key skills are understanding when AI is strong/weak and judging output quality.",
    "original_text": "The other thing to keep in mind is you know, you can study like how back propagation works, how neural NPS work you learn a sort of a certain set of skills which is interesting and if you really take that far to be like an AI developer, that can make you to, you know, one very interesting career. But I think most people who are using it in the space are going to be instead learning how to apply a life of problems. I actually think the most exciting thing is not building new AI methods. I think it's about finding what the right way they can be used. So I actually wouldn't say, I wouldn't say you need to learn everything about how AI works. I think the most important skills I need to understand when it's strong, when it's weak, when it's useful you need to be able to judge is that output good? Is it a hallucination? You need to be able to build systems which then can structure that and incorporate that. I think that's the most, the most useful set of skills but I wouldn't worry about I need to be an AI developer. I would instead take a very ground approach to, I just treat it like a tool right? It's like not magical it's not like amazing it's not like terrible. It's, you can go to your tool belt you could do a principal component analysis you could do an element call."
  },
  {
    "id": "sum_049",
    "summary": "Don't need to choose between being AI person or domain person—things are flexible; strong computational skills serve you well while learning to collaborate with domain experts.",
    "original_text": "First of all, I really appreciate your promotive talks and I have a quick question on deciding which major or which domain norms that I should choose on. Well, first of all, I'm a data science student and I'm studying the models as you mentioned of transformers for all the other various elms. The thing is that as I keep starting on, I think I should choose the domain that I should really delve into. But it seems that you already had the domain knowledge and then incorporated the technology into it. But for my case it's sort of the opposite. So I believe you've seen various cases but what kind of route or some devices do you have for the engineering students who try to learn the new domain knowledge and which one to apply the technology? Yeah a great question. I think things are more flexible. I think by the time I was in graduate school things were more flexible than people realize and I think now that they're more flexible. But it was that meaning I don't think you need to think about it like I'm an AI person or I'm a domain person because I think that these technologies because of the complexity of problems and the multi, it's possible to have a mix of skills and incorporate yourself into a project. So having very strong computational skills is, will always serve you well. You don't need to pick a particular specialization but I do think the skill to learn is to be able to talk with folks in a specialization and basically understand what, hear what their problems are think about how what you know can be useful to them."
  },
  {
    "id": "sum_050",
    "summary": "Start by showing something valuable to domain experts; approach with humility; teams have people from both computational and domain backgrounds working together.",
    "original_text": "Start by showing something valuable. Don't think at the start that you're going to know everything in advance. Come in and approach things with humility because in the team that I'm on, I came from a domain background but I came into computational work and other folks in the team pain from computational work making it into the life science domain. And so we work in the same area. There are things that I know that they don't know there are things that they know that I don't know as well. And the important thing is to understand how we work together and how we figure out like when these two ideas are going to be able to achieve something that we couldn't have come up with otherwise if that makes sense."
  },
  {
    "id": "sum_051",
    "summary": "Biology gets AI focus because people like human health, it integrates chemistry/physics, has extremely complex literature no human can fully read, and is first field where information exceeds human capacity.",
    "original_text": "Hello my name is sion song studying in Inter College recently I have heard that there was a lot of importance in AI for science and especially with that there was a lot of focus on the part of biology. I would like to know why there was a lot of focus on biology, especially compared to other parts such as physics or chemistry. Yeah this is a great question. I think there's a couple reasons. So one is that honestly people like biology because people like human health they do things to help human health, people feel good. So that's one thing that you'll encounter is that certain fields people will talk about a lot because they relate to things that resonate with. So that's one area but I think biocology has an especially large amount because it has this property of first off it integrates like chemistry is fundamental to biology physics is fundamental to biology. So it builds on top of these components. Now biology is like extremely complex in terms of its total literature. There's papers from all these different fields it's really highly multi disciplinary and as a result that it is at the first stage of this transition that we're seeing with AI. And that is that no human can read and understand everything that's going on. The amount of information is too complex, right? So a language Model will know things that no human can know because there are so many papers that it has read."
  },
  {
    "id": "sum_052",
    "summary": "Challenge is distinguishing true facts from hallucinations in AI models; chemistry and physics will undergo same transition as literature volume increases.",
    "original_text": "And so the challenge is to find out how those models can be useful, how they can have interesting true facts versus false hallucinations. And I think if that theory is true, then you will see chemistry and physics transition through that same space as the volume of literature increases. But another component is that there's a lot of specialized models for physics and chemistry like math based models, computational chemistry based models the things that I talked about those are also specialized models within genomics. I think it happens to be the case that specialized models in data rich environments have a greater relative advantage in physics and chemistry."
  },
  {
    "id": "sum_053",
    "summary": "Google builds computational methods at scale; clinicians have patient care expertise; partnership involves listening to clinical needs and following their requirements exactly.",
    "original_text": "This. So here the most important thing is the partners in the political space. So Google builds computational methods. That's our strength. Our strength is making them robust and engineering at scale, training animals to do things that other people can't do. But clinicians have strengths that we can't match. We don't run aloud we don't have it. So what we do is we listen to what the needs of those clinicians are. That Stanford project we're following we worked with the lead clinical scientists You and Ashley. We understand what it is that their clinicians need to make the diagnosis on every single case. We work with the genetic counselors and there in clinical practice, there's like very specific regulations, right about what you have to show in order to have a test. So this is the case where we are entirely following like we're asking what do you need the requirements to be? What do you need the properties to be? And we're letting the doctors who really understand the patients, really understand the disease and really understand the regulation to tell us exactly what we need to do and we don't do that ourselves. And actually that's one of the reasons why I truly love open source work because we open source things and then the people who know how to do that next step, they're the ones who are conducting."
  },
  {
    "id": "sum_054",
    "summary": "Validation depends on use case—genomic models use standard holdouts; phenotype models need orthogonal evidence like statistical tests and ontology enrichment unrelated to training.",
    "original_text": "Hello, My group is interested in health related AI program. So my question is when developing an AI Model, how do you validate its biological relevance or real world biological meaning? Bro this is a good question. So this is going to depend a lot on what they, I all utions are. So in the genomic space we have it kind of easy for validation in the sense that so for example, models are not training the bases that come off right? Like DNA of corn looks like DNA from human looks like DNA. There's actually not a whole lot of conceptual difference between the two. So we can use the standard processes of having holdouts and computational measurements because these don't really operate at the clinical level. Like training. A computational Model is very well understood in terms of the performance that it achieves. Now one of the things I didn't have a chance to talk about is this other work that we do which is more on the phenotype side. So you like pictures of people's eyes or radiograms, people's chests. Now there it's quite different because that one relates to like you can make a finding but the computational holdout is a little bit harder to have. So you look for these other orthogonal sets of evidence. So for example, we have a Model which will look at someone's eye and it will find the genetic variants that correlate with ID disease like glaucoma. And so the next step then is we can use those genetic variants on statistical tests that are unrelated to their discovery. So for example, we look for enrichment of something called ontologies, which are other characterizations that have been made in literature to see if this corresponds to for example eye development."
  },
  {
    "id": "sum_055",
    "summary": "Scientific validation involves building multiple orthogonal lines of evidence—looking for as many compelling independent examples as possible.",
    "original_text": "So like one of our papers, we have the list of variants. We show that those relate to I don't know the most. Like the best general way to describe this is you look for orthogonal sets of evidence that in no way relate to the thing that you are training on and you build this extra set of statist ical signals from each of those lines of evidence. And it's actually how we in general weigh scientifically in innovations within the space. You're looking for as many compelling examples as you possibly can find."
  },
  {
    "id": "sum_056",
    "summary": "AI decisions need expert oversight—present information to clinicians who make final calls; can quickly confirm findings; AI's role is making expert's job easier.",
    "original_text": "I have some question when making decisions through AI, how can we determine whether to trust its judgment or not? In our perspective, we are creating an invention that uses AI to classify things but the responsibility for its decisions is ultimately fall on us. But we are struggling to figure out how to approach this ethically and ensure that our design remains responsible and trust worthy. Yeah, it's, actually it's a very important question. So one of the things that you'll see so for example, in that's Stanford Sumy where we found a genitarian. What we did there is we present the information to a clinician and the clinician makes the decision. What we do is so sequence the whole genome is very complex but you can sequence a tiny bit very quickly. So one of the things you can do is you get the diagnosis and then you can quickly confirm the, the variant. I think that it's a judgment call by the doctor whether they want to proceed before the confirmation or not. And I believe in the case of Matthew, they actually had time in the case of the little girl I think that it was easy enough to give the compound. So one component of validation is to be able to have experts in the loop and I think that remains the best. The best way to make sure alien is reliable is you have people who are qualified and who really know and who can take accountability for a decision that's made. And then the challenge of the alien is different. Instead of asking the eye to solve the problem, you're really asking it to make the job of the expert easier right? And the bar to, to come over is do you save that expert time right? And it's still the expert's decision but you're helping them see more cases or be more reliable or not missed diagnos. That's always the best way to do it."
  },
  {
    "id": "sum_057",
    "summary": "Few AI systems ready for independent medical decisions; requires extensive regulatory validation with understood false positive/negative rates; expert in loop remains best practice.",
    "original_text": "Beyond that then you have, you know, I think honestly not many AI systems are ready to independently make decisions about the health of individuals. I think that the way that you do it there are standard regulatory processes that deal with like accredited tests where you've taken large sets of cases and you understand it's false positive rate, it's false negative rate and it, you know, there's a bar for approval and some of these are approved for like certain eye diseases, certain radiology AI. This large amount of work to validate the algorithm has occurred and so it can be done. I think it should be done with great effort and great statistical rigor and great care to make representative data sets. I think it remains the case that having an expert in the loop is the best way to do it. I think it will be it will be interesting to see if AI models can become so good that they give the confidence to overcome that transition and we feel like we can give more of them directly to faults. Hope hopefully this answered your question. It's like it's a it's definitely a complex one to answer at this time. I'm not sure I helped out with what your team might be wrestling with in the Model."
  },
  {
    "id": "sum_058",
    "summary": "Advanced AI systems use extensive statistics alongside deep learning—statistics structure input, do early screening, and use proper multiple test correction for genomic associations.",
    "original_text": "Hello, I'm studying in the college and my question is that when applying AI models to clinical genomics, how do you incorporate statistical uncertainty or error margins into decision making frameworks. Right? And so actually one thing that I want to mention is so I highlighted the deep learning work that our algorithm does but we actually use a lot of statistics. We use the statistics to structure the information that goes into the Model. And we also because there's so much information, we use statistics to sort of like do an early set of screening like to figure out what are the hard like, what can be solved with just statistics what are the hard challenges that come to require an AI? So in basically any advanced AI system, if you look under the hood, there's a lot of code that's written which is not like deep learning code which finds the right sets of problems to give to the AI models and then finds the right sets of problems to deal with with statistics. So I gave you that drug discovery example. So basically statistics are widely used in research cohorts. These are cases where you've gotten like I said, a million people for regeneron and they've got a whole bunch of examples of you know, this is an individual, this is their cholesterol, you know, this is their blood pressure and so on. And most of that is like building statistical tests. For this case, we have something called genome wide association studies. So we know there's three billion positions in the genome so we know how many tests we're making but we have the multiple test correction so we ask for a level of comp. So that's 10 to the minus 7. And so then we can run the statistical tests on all of the genetic variants that are present and then give this score."
  },
  {
    "id": "sum_059",
    "summary": "AI discovers variants, statistics validates them across populations—not every variant needs perfection since decisions are statistical across cohorts, not individual life-or-death.",
    "original_text": "And so it's this combination of the AI methods that I talked about discover the genetic variants. And then because this is like a million people, we don't need to worry too much about if every single one of them is absolutely correct because we're not going to make a life or death decision. We're instead asking the question of like statistically across this set of a million individuals like what are the variants associated with disease causing traits? So there's, and like when I talked about all the different types of computer models very, very quickly there's niches for each of those different approaches at this time it's not like everything is AI it's not like everything is statistics. It's really some combination of the two that you use depending on the research coort that you have or the clinical case you have."
  },
  {
    "id": "sum_060",
    "summary": "Clinical datasets have missingness requiring imputation, feature extraction from high-dimensional data, variational autoencoders for time series, and dimensional reduction preserving meaning.",
    "original_text": "Finding a relation or explaining the relation of other variables is difficult when integrating genomic and non genomic data. How your team heterogeneous data types and the statistical or machine learning or AI challenges of featuring harmonization and missing datas. Right? Actually this is a huge, a huge overhall question. It's very difficult to, because this is a lot of what we do how do I conven this down? So for one, clinical data sets have a lot of missingness and this forces a variety of different approaches. So one approach people use is imputation. This is used both in the genetic sets when you have low coverage sequencing. So you don't have the whole genome covered you use kind of reference data sets and you project predicted values there and you kind of record that these values are predicted. And so you incorporate that into the confidence models. One of the things that we use AI for quite a lot is in feature extraction. So one example is we have models which will take pictures of the retina and normally if you have a picture of a retina, it's a very high dimensional piece of information. It's hard to act on it right? So what these models have been trained on is a number of previously labeled data sets and they predict features of it and so that reduces the total dimensional data set and it produces like these structured feature comforts that you can operate on. The other thing that we do a lot is we use variational auto encoders to reconstruct signal. So and this is useful in a lot of time series. So for ECG or ECG is measurement of heart EPG is measurement of pulse spirometry is measurement of exhalation. These are each time series. And so we train auto encoders which have the task of reconstructing the input. And then those auto encoders produce effectively features. So you can take the principal components of what's in those auto encoders and then you have a reduced set of dimensions that you can incorporate into other work that you do."
  },
  {
    "id": "sum_061",
    "summary": "AI operates directly on raw messy data for dimensional reduction, then passes embeddings/principal components to downstream models like logistic regression for predictions.",
    "original_text": "So I guess the conclusion is a lot of what AI algorithms do in this kind of mesty a data space that has a lot of missingness is try to operate directly on the raw data to do dimensional reduction in a way that keeps them meeting that. Then you use downstream other models you pass in sets of embeddings, sets of those principal components like a logistic regression which is tasked with incorporating all of that information into some more binarized prodution."
  },
  {
    "id": "sum_062",
    "summary": "After training, examine explainability through attribution and middle layers; models can learn biology humans don't know, like genome duplications mistaken for bugs.",
    "original_text": "Hi my name is Hyan From interCollege and as our team is on our way of developing our device, I wanted to ask you based on the convolutional neural network Model used for genome analysis how does the Model one inherit picture from images and make informed decisions? Wow, it's a very hard question for him. You have to avoid any IPS. Interesting thing to do with models is after you train them is you look at things like explainability. So there's attribution basically. So you can do, you can trade models in a manner that you can preserve and look at the information in those middle layers. So we can go back and we can take hard examples and we have actually learned new things from biology from looking at what's in the middle of the neural network. So one example is that users kept reporting a bug to us like why doesn't eat variant call my variant and we look at it too and I'm like I don't know this looks like a variant to me it looks like a bug where's our bug? And we like really drill into it and we actually realize that the variants correct it's not a variant. This is a case where like a big region of the genome has been duplicated and moved into another spot right? So okay, models can learn things that even humans don't yet know."
  },
  {
    "id": "sum_063",
    "summary": "Understanding neural networks requires explainability work on surprising cases; CNNs learn like images—basic features early, complex structured concepts late, middle layers show abstractions.",
    "original_text": "If you want to understand what in that you actually have to really roll up your sleeves and do a bunch of explainability work and you look at surprising cases you look at a case that you think it's a bug and you try to really understand why is it being made so that's going from this way like what's the concept in the neural net learn from the output going from the other way like how do, how do convolutional neural networks learn? It remains very similar between genomics and images. At the lower levels of the network there's very basic features that have to do with like edge detection, shaped detection and like really basic stuff. And if you look in the network it at the first set of layers you don't see a lot of structure. And if you look at the network at the last layers, you see a lot of structure. The classes separate extremely well and the middle layers you see all these different structures that are involved at predicting certain parts of the problem at different levels of abstractness. Some of them work like closer to the raw data like is my sequencer a bad run or is this an aluminum machine or a pack bile machine or is this an insertion or a deletion? And then at the later levels we get really interesting concepts like this is a variant that was acquired after birth like it's like a cancer variant for example or this is a viral element in the human genome that you can actually trace out these explanations."
  },
  {
    "id": "sum_064",
    "summary": "Humans have self-awareness, identity, and decision-making ability that LLMs lack; LLMs are pliable mirrors with broader knowledge but poor synthesis—humans must remain deciders.",
    "original_text": "Hello my name is Park Junshang and I have a question about philosophical question. I originally came from a GATIST background but in this year I began studying mathematics and computer science and began interest in AI development. And recently it seems that AI is no longer just a technological tool, but it's starting to contribute to scientific discovery as well. It was shown the 2024 Nobel Prize in chemistry. Because of this, the boundary between German and Russian draws is becoming less clear in this new era. Is, do you think we are medically human in what kinds of work or thinking? Do you believe we can responsibility to Ai? I think everybody will give a different answer to this. And actually one of the important things is to find out what your answer is to this question. But I feel strongly about my so I think these AI models have remarkable capabilities but I actually don't think that they're very human in the way they work and that's good and bad. So the good thing is there are many things that humans do that. I think AI models only have just the merest shadow of like they might look like they can do some of it. But there's so much leaser than humans and that's introspection like it's thinking about what you know, you know what you know you don't know. It's this kind of like actually self awareness and self awareness is like a very important skill to overall develop like understand for yourself like, What are your thought processes that are reliable? What are your thought processes that are unreliable? What are the biases that you have? Like if you know, it's just a generally good skill LMS truly have they intrinsically don't have self awareness right? Because they, they don't know that they're not minds. They're these mirrors like they're mirrors trained on everything in the human language. It's like a, it's like a Gallum or kind of like a mirror image. So a human always has to be the decider. I think humans are better at decision. Humans are better at self awareness. Human LL models are too pliable. They like will do whatever you want like to two readily they have no identity. Humans have identity now where MLM models are strong as they have broader knowledge like I guarantee you every AI Model knows more than me about virtually everything, right? But they're not as good at synthesizing it."
  },
  {
    "id": "sum_065",
    "summary": "Treat AI as tools for searching information and generating hypotheses, but humans must verify truth and decide what's worth experimenting—never trust outputs blindly.",
    "original_text": "So the best way to work with the Model is to try to try to pick out what information is there Ask a question don't trust anything that comes out of it like treat it as a variety of different opinions. Treat it as a way to search literature or look at novel hypotheses. But you should always know that an AI can propose a novel hypothesis. But figuring out if that's worth doing an experiment on figuring out whether it's true only a human can do that right now because only a human has the self awareness and identity and it's really the ability to make decisions. Now I don't know if that's going to change. I think the models are going to get better at what they currently do. I don't think language models will so easily overcome the limitations that I talked about but I think the way that I relate to these models is they are tools, right? I want to see what's the information in them. I'll never treat them as if they gave me a correct answer. I'll allow you to get upset at them if they gave me a hallucination. You know, I ran a program and I got an output. The best way is for me to figure out how I can run that program 100 different times and arrive at a better decision with them. And if you treat them as tools which are and if you have the humility to realize that they will be conditionally stronger than you in certain ways and that doesn't actually threaten their identity I think my opinion is it's the best way to relate to them but everybody's got to figure that out for themselves and in five years it could only be different."
  }
]