# summarizing-llm-fine-tuning


>> Running prepare_tf_dataset will bring you ds_tok
>> <br>Running model will provide you out-tf (model is inside)
>> <br>Running run_model will give you short summarizing for your example_text
>> <br>Running eval_rouge (edit the generated and original text from your own) will give you rouge score

It was simply created by chatgpt and from 
<br>https://huggingface.co/docs/transformers/ko/tasks/summarization
<br>and
<br>https://huggingface.co/docs/transformers/ko/training#train-a-tensorflow-model-with-keras

env:
<br>pip install "tensorflow==2.20.0" "tf-keras==2.20.1"
<br>pip install "transformers==4.44.2" "datasets>=2.20.0" "tokenizers==0.19.1" "safetensors>=0.4.4"
<br>pip install huggingface_hub
<br>pip install ipywidgets
<br>pip install datasets



<br>Have a nice gamuuuuu
